{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "from torch import nn\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "# sampling \n",
    "def downsampling(data, ratio):\n",
    "    majority = data[data[\"target\"] == 0]\n",
    "    minority = data[data[\"target\"] == 1]\n",
    "    lower_majority = majority.sample(n=int(ratio*len(minority)), replace=False, random_state=20, axis=0)\n",
    "    return pd.concate([lower_majority, minority])\n",
    "   \n",
    "def evaluation(outputs, labels):\n",
    "    # outputs => probability (float)\n",
    "    # labels => labels\n",
    "    outputs[outputs>=0.5] = 1 # 大於等於 0.5 為正面\n",
    "    outputs[outputs<0.5] = 0 # 小於 0.5 為負面\n",
    "    correct = torch.sum(torch.eq(outputs, labels)).item()\n",
    "    return correct\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    text: string\n",
    "    return: list of word\n",
    "    \"\"\"\n",
    "    return utils.simple_preprocess(text) #lower case, deaccent, remove punctuation, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training word2vec model on quora data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "\n",
    "# train word to vector\n",
    "def train_word2vec(x):\n",
    "    model = word2vec.Word2Vec(x, size=250, window=5, min_count=5, workers=12, iter=10, sg=1)\n",
    "    return model\n",
    "if False:\n",
    "    print(\"Loading training data\")\n",
    "    train = pd.read_csv(data_path + \"train.csv\")\n",
    "    sentences = train[\"question_text\"].apply(utils.simple_preprocess)\n",
    "\n",
    "    model = train_word2vec(sentences)\n",
    "    print(\"saving model ...\")\n",
    "    model.save(w2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://colab.research.google.com/drive/16d1Xox0OW-VNuxDn1pvy2UXFIPfieCb9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embed(typeToLoad):\n",
    "    def get_coefs(word, *arr):\n",
    "        return word, np.asarray(arr, dtype='float16')\n",
    "\n",
    "    if typeToLoad == \"glove\":\n",
    "        file = 'embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding = \"utf8\", errors='ignore') if len(o) > 100)\n",
    "    elif typeToLoad == \"word2vec\":\n",
    "        # file = 'embeddings⁩/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin⁩'\n",
    "        file = 'embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "        embeddings_index = KeyedVectors.load_word2vec_format(file, binary=True)  # query word vector from the file\n",
    "    elif typeToLoad == \"fasttext\":\n",
    "        # file = \"⁨embeddings⁩/wiki-news-300d-1M⁩/wiki-news-300d-1M.vec\"\n",
    "        file = 'embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin', errors='ignore'))\n",
    "    elif typeToLoad == \"paragram\":\n",
    "        file = 'embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding = \"utf8\", errors='ignore') )\n",
    "    elif typeToLoad == 'trained_word2vec':\n",
    "        file = w2v_path\n",
    "        embeddings_index = Word2Vec.load(file)\n",
    "\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self, sentences, embedding, embedding_dim):\n",
    "        self.sentences = sentences\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.idx2word = []\n",
    "        self.word2idx = {}\n",
    "        self.embedding_matrix = []\n",
    "        \n",
    "    def add_embedding(self,word):\n",
    "        #use random vector to represent words not in word embedding model, euch as UNK\n",
    "        vector = torch.empty(1, self.embedding_dim, dtype=torch.float)\n",
    "        torch.nn.init.uniform_(vector)\n",
    "        self.word2idx[word] = len(self.word2idx)\n",
    "        self.idx2word.append(word)\n",
    "        self.embedding_matrix = torch.cat([self.embedding_matrix.float(), vector], 0)\n",
    "        \n",
    "    def make_embedding(self):\n",
    "        #make embedding matrix\n",
    "        print(\"Making embedding...\")\n",
    "        for word, vector in self.embedding.items():\n",
    "            self.word2idx[word] = len(self.word2idx)\n",
    "            self.idx2word.append(word)\n",
    "            self.embedding_matrix.append(vector)\n",
    "        print(\"loop is done\")\n",
    "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
    "        self.add_embedding(\"<PAD>\")\n",
    "        self.add_embedding(\"<UNK>\")\n",
    "        print(\"total words {}\".format(len(self.embedding_matrix)))\n",
    "        return self.embedding_matrix\n",
    "    \n",
    "    def pad_sentence(self, sentence, max_len=20):\n",
    "        if len(sentence) > max_len:\n",
    "            sentence = sentence[:max_len]\n",
    "        else:\n",
    "            pad_len = max_len - len(sentence)\n",
    "            for _ in range(pad_len):\n",
    "                sentence.append(self.word2idx[\"<PAD>\"])\n",
    "        assert len(sentence) == max_len\n",
    "        return sentence\n",
    "    \n",
    "    def sentence_word2idx(self, max_len):\n",
    "        sentence_list = []\n",
    "        for i, sen in enumerate(self.sentences):\n",
    "            print(\"sentence count #{}\".format(i+1), end='\\r')\n",
    "            sentence_idx = []\n",
    "            for word in sen:\n",
    "                if word in self.word2idx.keys():\n",
    "                    sentence_idx.append(self.word2idx[word])\n",
    "                else:\n",
    "                    sentence_idx.append(self.word2idx[\"<UNK>\"])\n",
    "            sentence_idx = self.pad_sentence(sentence_idx, max_len)\n",
    "            sentence_list.append(sentence_idx)\n",
    "        return torch.LongTensor(sentence_list)\n",
    "    \n",
    "    def labels_to_tensor(self, y):\n",
    "        y = [int(label) for label in y]\n",
    "        return torch.LongTensor(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-3fca6357f83b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "vector = torch.empty(1, 300, dtype=torch.float)\n",
    "torch.nn.init.uniform_(vector)\n",
    "torch.cat([preprocess.embedding_matrix.float(), vector], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-02839585a8ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<PAD>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<UNK>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-f8e986e2df1a>\u001b[0m in \u001b[0;36madd_embedding\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "preprocess.add_embedding(\"<PAD>\")\n",
    "preprocess.add_embedding(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset for dataLoader\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class CustomDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Expected data shape like:(data_num, data_len)\n",
    "    Data can be a list of numpy array or a list of lists\n",
    "    input data shape : (data_num, seq_len, feature_dim)\n",
    "    \n",
    "    __len__ will return the number of data\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        self.label = y\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is None: return self.data[idx]\n",
    "        return self.data[idx], self.label[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class LSTM_Net(nn.Module):\n",
    "    def __init__(self, embedding, embedding_dim, hidden_dim, num_layers, dropout=0.5, fix_embedding=True):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        # embedding layer\n",
    "        self.embedding = torch.nn.Embedding(embedding.size(0),embedding.size(1))\n",
    "        self.embedding.weight = torch.nn.Parameter(embedding)\n",
    "        # if fix_embedding is False, embedding weight wont be updated\n",
    "        self.embedding.weight.requires_grad = False if fix_embedding else True\n",
    "        self.embedding_dim = embedding.size(1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.classifier = nn.Sequential( nn.Dropout(dropout),\n",
    "                                         nn.Linear(hidden_dim, 1),\n",
    "                                         nn.Sigmoid() )\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.embedding(inputs)\n",
    "        x, _ = self.lstm(inputs, None)\n",
    "        # x 的 dimension (batch, seq_len, hidden_size)\n",
    "        # 取用 LSTM 最後一層的 hidden state\n",
    "        x = x[:, -1, :] \n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def training(batch_size, n_epoch, lr, model_dir, train, valid, model, device):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('\\nstart training, parameter total:{}, trainable:{}\\n'.format(total, trainable))\n",
    "    \n",
    "    criterion = nn.BCELoss() #binary cross entropy loss function \n",
    "    t_batch = len(train) \n",
    "    v_batch = len(valid) \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # \n",
    "    total_loss, total_acc, best_acc = 0, 0, 0\n",
    "    for epoch in range(n_epoch):\n",
    "        \n",
    "        model.train() # training mode, weights are updated\n",
    "        total_loss, total_acc = 0, 0\n",
    "        # training module\n",
    "        for i, (inputs, labels) in enumerate(train):\n",
    "            inputs = inputs.to(device, dtype=torch.long) \n",
    "            labels = labels.to(device, dtype=torch.float) \n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs) \n",
    "            outputs = outputs.squeeze() \n",
    "            loss = criterion(outputs, labels) # compute training loss\n",
    "            loss.backward() # 算 loss 的 gradient\n",
    "            optimizer.step() \n",
    "            correct = evaluation(outputs, labels)\n",
    "            total_acc += (correct / batch_size)\n",
    "            total_loss += loss.item()\n",
    "            print('[ Epoch{}: {}/{} ] loss:{:.3f} acc:{:.3f} '.format(\n",
    "            \tepoch+1, i+1, t_batch, loss.item(), correct*100/batch_size), end='\\r')\n",
    "        print('\\nTrain | Loss:{:.5f} Acc: {:.3f}'.format(total_loss/t_batch, total_acc/t_batch*100))\n",
    "\n",
    "        # validation module\n",
    "        model.eval() # fixed weights\n",
    "        with torch.no_grad(): #disables tracking of gradients in autograd.\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for i, (inputs, labels) in enumerate(valid):\n",
    "                inputs = inputs.to(device, dtype=torch.long) \n",
    "                labels = labels.to(device, dtype=torch.float) \n",
    "                outputs = model(inputs) \n",
    "                outputs = outputs.squeeze() \n",
    "                loss = criterion(outputs, labels) \n",
    "                correct = evaluation(outputs, labels) \n",
    "                total_acc += (correct / batch_size)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            print(\"Valid | Loss:{:.5f} Acc: {:.3f} \".format(total_loss/v_batch, total_acc/v_batch*100))\n",
    "            if total_acc > best_acc:\n",
    "                best_acc = total_acc\n",
    "                torch.save(model, \"{}/ckpt.model\".format(model_dir))\n",
    "                print('saving model with acc {:.3f}'.format(total_acc/v_batch*100))\n",
    "        print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def testing(batch_size, test_loader, model, device):\n",
    "    model.eval()\n",
    "    ret_output = []\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(tqdm(test_loader)):\n",
    "            inputs = inputs.to(device, dtype=torch.long)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(0) #squeeze removes all demensions with input size of 1, squeeze(0) only \n",
    "            outputs[outputs>=0.5] = 1 # 大於等於 0.5 為正面\n",
    "            outputs[outputs<0.5] = 0 # 小於 0.5 為負面\n",
    "            ret_output += outputs.int().tolist()\n",
    "    \n",
    "    return ret_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from gensim.models import word2vec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.chdir(\"../quora-insincere-questions-classification/\")\n",
    "print(os.getcwd())\n",
    "\n",
    "data_path = \"./\"\n",
    "output_path = \"result/\"\n",
    "w2v_path = os.path.join(output_path, 'w2v_all.model')\n",
    "embedding_dim = 300\n",
    "cv_n = 5\n",
    "train_ratio = 0.2\n",
    "val_ratio = 0.01\n",
    "sen_len = 20\n",
    "fix_embedding = True # fix embedding during training\n",
    "batch_size = 256\n",
    "epoch = 5\n",
    "lr = 0.001\n",
    "model_dir = output_path # model directory for checkpoint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embedding\")\n",
    "glove_embedding = load_embed(\"glove\")\n",
    "paragram_embedding = load_embed(\"paragram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2912338/2912338 [01:47<00:00, 26969.08it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Combining embedding\")\n",
    "corpus = set(list(glove_embedding.keys()) + list(paragram_embedding.keys()))\n",
    "init_vector = [0]*embedding_dim\n",
    "embedding = dict()\n",
    "for word in tqdm(corpus):\n",
    "    glove_vector = glove_embedding.get(word, init_vector)\n",
    "    paragram_vector = paragram_embedding.get(word, init_vector)\n",
    "    vector = 0.7*np.asarray(glove_vector) + 0.3*np.asarray(paragram_vector)\n",
    "    embedding[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del glove_embedding\n",
    "del paragram_embedding\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del corpus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Loading training data\")\n",
    "train = pd.read_csv(data_path + \"train.csv\")\n",
    "train_x, y = train[\"question_text\"], train[\"target\"]\n",
    "train_x = train_x.apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making embedding...\n",
      "loop is done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-f8e986e2df1a>\u001b[0m in \u001b[0;36mmake_embedding\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loop is done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<PAD>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<UNK>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"total words {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-f8e986e2df1a>\u001b[0m in \u001b[0;36madd_embedding\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 3494806800 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess training data\n",
    "preprocess = Preprocess(train_x, embedding, embedding_dim)\n",
    "embedding_matrix = preprocess.make_embedding()\n",
    "train_x = preprocess.sentence_word2idx(max_len=sen_len)\n",
    "y = preprocess.labels_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence count #52\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'<UNK>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-1cb6cdb28da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence_word2idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msen_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-3fd4506a7576>\u001b[0m in \u001b[0;36msentence_word2idx\u001b[1;34m(self, max_len)\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0msentence_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0msentence_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"<UNK>\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0msentence_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0msentence_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '<UNK>'"
     ]
    }
   ],
   "source": [
    "#train_x = preprocess.sentence_word2idx(max_len=sen_len)\n",
    "y = preprocess.labels_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Making embedding...\n",
      "loop is done48488\n",
      "total words 48490\n",
      "train size 219011, validation size 2213\n",
      "\n",
      "start training, parameter total:12363851, trainable:241351\n",
      "\n",
      "[ Epoch1: 856/856 ] loss:0.112 acc:47.656 \n",
      "Train | Loss:0.14956 Acc: 94.577\n",
      "Valid | Loss:0.11292 Acc: 91.667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Helen Guo\\anaconda3\\envs\\env_torch\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LSTM_Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 91.667\n",
      "-----------------------------------------------\n",
      "[ Epoch2: 856/856 ] loss:0.102 acc:48.828 \n",
      "Train | Loss:0.12009 Acc: 95.171\n",
      "Valid | Loss:0.10908 Acc: 92.188 \n",
      "saving model with acc 92.188\n",
      "-----------------------------------------------\n",
      "[ Epoch3: 856/856 ] loss:0.126 acc:49.219 \n",
      "Train | Loss:0.11493 Acc: 95.402\n",
      "Valid | Loss:0.10638 Acc: 92.231 \n",
      "saving model with acc 92.231\n",
      "-----------------------------------------------\n",
      "[ Epoch4: 856/856 ] loss:0.066 acc:49.219 \n",
      "Train | Loss:0.11105 Acc: 95.523\n",
      "Valid | Loss:0.10549 Acc: 92.405 \n",
      "saving model with acc 92.405\n",
      "-----------------------------------------------\n",
      "[ Epoch5: 856/856 ] loss:0.141 acc:48.047 \n",
      "Train | Loss:0.10739 Acc: 95.675\n",
      "Valid | Loss:0.10358 Acc: 92.144 \n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.t=metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#cv\n",
    "skf = StratifiedKFold(n_split=cv_n)\n",
    "cv_k = 0\n",
    "resuls = []\n",
    "for train_index, test_index in skf.split(train_x, y):\n",
    "    cv_k += 1\n",
    "    print(\"--------- cv\", cv_k)\n",
    "    X_train, y_train = train_x[train_index], y[train_index]\n",
    "    X_test, y_test = train_x[test_index], y[test_index]\n",
    "    \n",
    "    train_len = int(len(X_train) * (1-val_ratio))\n",
    "    X_train, X_val, y_train, y_val = X_train[:train_len], X_train[train_len:], y_train[:train_len], y_train[train_len:]\n",
    "    print(\"train size {}, validation size {}\".format(train_len, len(X_train) - train_len))\n",
    "\n",
    "    train_dataset = CustomDataset(X=X_train, y=y_train)\n",
    "    val_dataset = CustomDataset(X=X_val, y=y_val)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 0)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = False,\n",
    "                                                num_workers = 0)\n",
    "\n",
    "    model = LSTM_Net(embedding_matrix, \\\n",
    "                     embedding_dim=embedding_dim, \\\n",
    "                     hidden_dim=150, num_layers=1, dropout=0.5, fix_embedding=fix_embedding)\n",
    "    model = model.to(device) \n",
    "    \n",
    "    print(\"Training\")\n",
    "    model_path = os.path.join(model_dir,f'qiqc_cv{cv_k}.model'\n",
    "    training(batch_size, epoch, lr, model_path, train_loader, val_loader, model, device)\n",
    "    \n",
    "    print(\"Testing\")\n",
    "    test_dataset = CustomDataset(X=X_test, y=None)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = False,\n",
    "                                                num_workers = 0)\n",
    "    print('\\nload model ...')\n",
    "    model = torch.load(model_path)\n",
    "    outputs = testing(batch_size, test_loader, model, device)\n",
    "    f1 = f1_score(y_test, outputs)\n",
    "    print(\"f1 score\", f1)\n",
    "    results.append(f1)\n",
    "print(\"Average cv score\", np.mean(results) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading embedding\")\n",
    "glove_embedding = load_embedding(\"glove\")\n",
    "paragram_embedding = load_embedding(\"paragram\")\n",
    "\n",
    "print(\"Combining embedding\")\n",
    "corpus = set(list(glove_embedding.keys()) + list(paragram_embedding.keys()))\n",
    "init_vector = [0]*embedding_dim\n",
    "embedding = []\n",
    "for word in tdqm(corpus):\n",
    "    glove_vector = glove_embedding.get(word, init_vector)\n",
    "    paragram_vector = paragram_embedding.get(word, init_vector)\n",
    "    vector = 0.7*np.asarray(glove_vector) + 0.3*np.asarray(paramgram_vector)\n",
    "    embedding.append(vector)\n",
    "del glove_embedding\n",
    "del paragram_embedding\n",
    "gc.collect()\n",
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Making embedding...\n",
      "loop is done48488\n",
      "total words 48490\n",
      "train size 219011, validation size 2213\n",
      "\n",
      "start training, parameter total:12363851, trainable:241351\n",
      "\n",
      "[ Epoch1: 856/856 ] loss:0.112 acc:47.656 \n",
      "Train | Loss:0.14956 Acc: 94.577\n",
      "Valid | Loss:0.11292 Acc: 91.667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Helen Guo\\anaconda3\\envs\\env_torch\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LSTM_Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model with acc 91.667\n",
      "-----------------------------------------------\n",
      "[ Epoch2: 856/856 ] loss:0.102 acc:48.828 \n",
      "Train | Loss:0.12009 Acc: 95.171\n",
      "Valid | Loss:0.10908 Acc: 92.188 \n",
      "saving model with acc 92.188\n",
      "-----------------------------------------------\n",
      "[ Epoch3: 856/856 ] loss:0.126 acc:49.219 \n",
      "Train | Loss:0.11493 Acc: 95.402\n",
      "Valid | Loss:0.10638 Acc: 92.231 \n",
      "saving model with acc 92.231\n",
      "-----------------------------------------------\n",
      "[ Epoch4: 856/856 ] loss:0.066 acc:49.219 \n",
      "Train | Loss:0.11105 Acc: 95.523\n",
      "Valid | Loss:0.10549 Acc: 92.405 \n",
      "saving model with acc 92.405\n",
      "-----------------------------------------------\n",
      "[ Epoch5: 856/856 ] loss:0.141 acc:48.047 \n",
      "Train | Loss:0.10739 Acc: 95.675\n",
      "Valid | Loss:0.10358 Acc: 92.144 \n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# preprocess training data\n",
    "preprocess = Preprocess(train_x, embedding, embedding_dim)\n",
    "embedding_matrix = preprocess.make_embedding()\n",
    "train_x = preprocess.sentence_word2idx(max_len=sen_len)\n",
    "y = preprocess.labels_to_tensor(y)\n",
    "\n",
    "\n",
    "%%\n",
    "#cv\n",
    "skf = StratifiedKFold(n_split=cv_n)\n",
    "for train_index, test_index in skf.split(train_x, y):\n",
    "    X_train, y_train = train_X[]\n",
    "train_len = int(len(sample_train) * (1-val_ratio))\n",
    "X_train, X_val, y_train, y_val = train_x[:train_len], train_x[train_len:], y[:train_len], y[train_len:]\n",
    "print(\"train size {}, validation size {}\".format(train_len, len(sample_train) - train_len))\n",
    "\n",
    "train_dataset = CustomDataset(X=X_train, y=y_train)\n",
    "val_dataset = CustomDataset(X=X_val, y=y_val)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = True,\n",
    "                                            num_workers = 0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = False,\n",
    "                                            num_workers = 0)\n",
    "\n",
    "model = LSTM_Net(embedding, embedding_dim=250, hidden_dim=150, num_layers=1, dropout=0.5, fix_embedding=fix_embedding)\n",
    "model = model.to(device) \n",
    "\n",
    "training(batch_size, epoch, lr, model_dir, train_loader, val_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making embedding...\n",
      "loop is done48488\n",
      "total words 48490\n",
      "sentence count #200000\n",
      "load model ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-70fd663bcd20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_x = test0[\"question_text\"].apply(tokenize_text)\n",
    "test_y = test0[\"target\"]\n",
    "\n",
    "preprocess = Preprocess(test_x, sen_len, w2v_path=w2v_path)\n",
    "embedding = preprocess.make_embedding(load=True)\n",
    "test_x = preprocess.sentence_word2idx()\n",
    "\n",
    "test_dataset = CustomDataset(X=test_x, y=None)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = False,\n",
    "                                            num_workers = 0)\n",
    "print('\\nload model ...')\n",
    "model = torch.load(os.path.join(model_dir, 'ckpt.model'))\n",
    "outputs = testing(batch_size, test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5792168389115387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(test_y, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on submitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data\n",
      "Making embedding...\n",
      "loop is done48488\n",
      "total words 48490\n",
      "sentence count #375806\n",
      "load model ...\n",
      "save csv ...\n",
      "Finish Predicting\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data\")\n",
    "test = pd.read_csv(data_path + \"test.csv\")\n",
    "test_x = test[\"question_text\"].apply(tokenize_text)\n",
    "\n",
    "preprocess = Preprocess(test_x, embedding, embedding_dim)\n",
    "embedding = preprocess.make_embedding()\n",
    "test_x = preprocess.sentence_word2idx(max_len = sen_len)\n",
    "\n",
    "test_dataset = CustomDataset(X=test_x, y=None)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = False,\n",
    "                                            num_workers = 0)\n",
    "print('\\nload model ...')\n",
    "model = torch.load(os.path.join(model_dir, 'qiqc1.model'))\n",
    "outputs = testing(batch_size, test_loader, model, device)\n",
    "\n",
    "tmp = pd.DataFrame({\"id\":[str(i) for i in range(len(test_x))],\"label\":outputs})\n",
    "print(\"save csv ...\")\n",
    "tmp.to_csv(os.path.join(output_path, 'predict.csv'), index=False)\n",
    "print(\"Finish Predicting\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
