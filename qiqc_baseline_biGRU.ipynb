{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qiqc_baseline_biGRU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfRQlbP7nRgGApRBEb5pDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HelenGuohx/Quora-Insincere-Questions/blob/master/qiqc_baseline_biGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8beunMovsaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJtuIkmpv320",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "f2b34221-237b-4cb0-b96f-d887f0656b68"
      },
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 57% 9.00M/15.8M [00:00<00:00, 23.9MB/s]\n",
            "100% 15.8M/15.8M [00:00<00:00, 40.0MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 4.09M/4.09M [00:00<00:00, 17.2MB/s]\n",
            "\n",
            "Downloading embeddings.zip to /content\n",
            "100% 5.95G/5.96G [01:39<00:00, 61.5MB/s]\n",
            "100% 5.96G/5.96G [01:39<00:00, 64.2MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 89% 49.0M/54.9M [00:01<00:00, 33.7MB/s]\n",
            "100% 54.9M/54.9M [00:01<00:00, 51.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qruLz9JuwAhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "62f7d73f-770c-4793-e267-134348ef573a"
      },
      "source": [
        "!unzip embeddings.zip -d embeddings"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  embeddings.zip\n",
            "   creating: embeddings/GoogleNews-vectors-negative300/\n",
            "   creating: embeddings/glove.840B.300d/\n",
            "   creating: embeddings/paragram_300_sl999/\n",
            "   creating: embeddings/wiki-news-300d-1M/\n",
            "  inflating: embeddings/glove.840B.300d/glove.840B.300d.txt  \n",
            "  inflating: embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \n",
            "  inflating: embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec  \n",
            "  inflating: embeddings/paragram_300_sl999/README.txt  \n",
            "  inflating: embeddings/paragram_300_sl999/paragram_300_sl999.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aP7ydt-TsPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asmdW0ryvhGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOor_z6DYqNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_sentence(sentences, max_features,maxlen):\n",
        "    \"\"\"\n",
        "    sentences: string \n",
        "    max_features: int, maximum number of words\n",
        "    return: sentences, a list of indices\n",
        "            word_index, a dict of word and index pair\n",
        "    \"\"\"\n",
        "    ## Tokenize the sentences\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    sentences = tokenizer.texts_to_sequences(sentences)\n",
        "    ## Pad the sentences \n",
        "    sentences = pad_sequences(sentences, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n",
        "    return sentences, tokenizer.word_index"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w82wPyAZRW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "eb92da43-74ee-40df-96ca-6fa8025e33f5"
      },
      "source": [
        "tokenize_sentence([\"i'm could going to buy     an apple\", \"couldn't u take me to the store?\", \"call me at 32543t5 sfgf.;''''\"], \\\n",
        "                  100, 10)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 3,  4,  5,  1,  6,  7,  8,  0,  0,  0],\n",
              "        [ 9, 10, 11,  2,  1, 12, 13,  0,  0,  0],\n",
              "        [14,  2, 15, 16, 17, 18,  0,  0,  0,  0]], dtype=int32),\n",
              " {\"''''\": 18,\n",
              "  '32543t5': 16,\n",
              "  'an': 7,\n",
              "  'apple': 8,\n",
              "  'at': 15,\n",
              "  'buy': 6,\n",
              "  'call': 14,\n",
              "  'could': 4,\n",
              "  \"couldn't\": 9,\n",
              "  'going': 5,\n",
              "  \"i'm\": 3,\n",
              "  'me': 2,\n",
              "  'sfgf': 17,\n",
              "  'store': 13,\n",
              "  'take': 11,\n",
              "  'the': 12,\n",
              "  'to': 1,\n",
              "  'u': 10})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2x2ZIdBwx0M",
        "colab_type": "text"
      },
      "source": [
        "### Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT78TAyRwPOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embedding(typeToLoad, word_index, max_words):\n",
        "    def get_coefs(word, *arr):\n",
        "        return word, np.asarray(arr, dtype='float16')\n",
        "\n",
        "    embeddings_index = {}\n",
        "    if typeToLoad == \"glove\":\n",
        "        file = 'embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
        "    elif typeToLoad == \"word2vec\":\n",
        "        file = 'embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
        "        embeddings_index = KeyedVectors.load_word2vec_format(file, binary=True)  # query word vector from the file\n",
        "    elif typeToLoad == \"fasttext\":\n",
        "        file = 'embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
        "    elif typeToLoad == \"paragram\":\n",
        "        file = 'embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding = \"utf8\", errors='ignore') )\n",
        "    return embeddings_index\n",
        "  \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "    embed_size = all_embs.shape[1]\n",
        "    num_word = min(max_words, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size)) #init embedding matrix\n",
        "    for word, index in word_index.items():\n",
        "      if index > max_words: continue\n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      if embedding_vector is not None: embedding_matrix[index] = embedding_vector\n",
        "    return embedding_matrix\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNSm7uD12vhi",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbkjdyep2msy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "06fdb6cb-3a91-4e8f-9010-0586c0523900"
      },
      "source": [
        "%%time\n",
        "spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\x10', '\\x7f', '\\x9d', '\\xad', '\\xa0']\n",
        "\n",
        "# with open('src/rare_words.json') as f:\n",
        "#      rare_words_mapping = json.load(f)\n",
        "\n",
        "# with open('src/misspell_words.json') as f:\n",
        "#      misspell_words_mapping = json.load(f)\n",
        "\n",
        "# stop_words = stopwords.words('english')\n",
        "\n",
        "# replace unicode space character with space ' '\n",
        "def replace_space(text):\n",
        "    for s in spaces:\n",
        "        text = text.replace(s, ' ')\n",
        "    return text\n",
        "\n",
        "def clean_rare_words(text):\n",
        "    for w in rare_words_mapping:\n",
        "        if text.count(w) > 0:\n",
        "            text = text.replace(w, rare_words_mapping[w])\n",
        "    return text\n",
        "\n",
        "def clean_decontracted(text):\n",
        "    # specific\n",
        "    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n",
        "    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n",
        "    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n",
        "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n",
        "\n",
        "    # general\n",
        "    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n",
        "    text = re.sub(r\"(A|a)in(\\'|\\’)t \", \"is not \", text)\n",
        "    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)s \", \" is \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def clean_misspell(text):\n",
        "    for w in misspell_words_mapping:\n",
        "        if text.count(w) > 0:\n",
        "            text = text.replace(w, misspell_words_mapping[w])\n",
        "    return text\n",
        "\n",
        "\n",
        "# replace punctuation with space\n",
        "def replace_punctuation(text):\n",
        "    punct = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    return text.translate(punct)\n",
        "\n",
        "\n",
        "# clean repeated letters\n",
        "def clean_repeat_words(text):\n",
        "    text = text.replace(\"img\", \"ing\")\n",
        "    text = re.sub(r\"(I|i)(I|i)+ng\", \"ing\", text)\n",
        "    text = re.sub(r\"(L|l)(L|l)(L|l)+y\", \"lly\", text)\n",
        "    text = re.sub(r\"(A|a)(A|a)(A|a)+\", \"a\", text)\n",
        "    text = re.sub(r\"(C|c)(C|c)(C|c)+\", \"cc\", text)\n",
        "    text = re.sub(r\"(D|d)(D|d)(D|d)+\", \"dd\", text)\n",
        "    text = re.sub(r\"(E|e)(E|e)(E|e)+\", \"ee\", text)\n",
        "    text = re.sub(r\"(F|f)(F|f)(F|f)+\", \"ff\", text)\n",
        "    text = re.sub(r\"(G|g)(G|g)(G|g)+\", \"gg\", text)\n",
        "    text = re.sub(r\"(I|i)(I|i)(I|i)+\", \"i\", text)\n",
        "    text = re.sub(r\"(K|k)(K|k)(K|k)+\", \"k\", text)\n",
        "    text = re.sub(r\"(L|l)(L|l)(L|l)+\", \"ll\", text)\n",
        "    text = re.sub(r\"(M|m)(M|m)(M|m)+\", \"mm\", text)\n",
        "    text = re.sub(r\"(N|n)(N|n)(N|n)+\", \"nn\", text)\n",
        "    text = re.sub(r\"(O|o)(O|o)(O|o)+\", \"oo\", text)\n",
        "    text = re.sub(r\"(P|p)(P|p)(P|p)+\", \"pp\", text)\n",
        "    text = re.sub(r\"(Q|q)(Q|q)+\", \"q\", text)\n",
        "    text = re.sub(r\"(R|r)(R|r)(R|r)+\", \"rr\", text)\n",
        "    text = re.sub(r\"(S|s)(S|s)(S|s)+\", \"ss\", text)\n",
        "    text = re.sub(r\"(T|t)(T|t)(T|t)+\", \"tt\", text)\n",
        "    text = re.sub(r\"(V|v)(V|v)+\", \"v\", text)\n",
        "    text = re.sub(r\"(Y|y)(Y|y)(Y|y)+\", \"y\", text)\n",
        "    text = re.sub(r\"plzz+\", \"please\", text)\n",
        "    text = re.sub(r\"(Z|z)(Z|z)(Z|z)+\", \"zz\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def lower_words(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    new_words = []\n",
        "    for w in words:\n",
        "        if w not in stop_words and w != ' ':\n",
        "            new_words.append(w)\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def stemming(text):\n",
        "    pass\n",
        "\n",
        "# apply all the clean methods\n",
        "def text_cleaning(text):\n",
        "    text = replace_space(text)\n",
        "    text = clean_decontracted(text)\n",
        "    text = replace_punctuation(text)\n",
        "    text = lower_words(text)\n",
        "    text = clean_repeat_words(text)\n",
        "    # text = clean_rare_words(text)\n",
        "    # text = clean_misspell(text)\n",
        "    # text = remove_stopwords(text)\n",
        "    return text"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14 µs, sys: 1 µs, total: 15 µs\n",
            "Wall time: 19.1 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ2ryCX22y0E",
        "colab_type": "text"
      },
      "source": [
        "### statistic feactures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT50DkKG218U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWDXYLfH2_2A",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VHoZ2h93CMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU_Net(nn.Module):\n",
        "  def __init__(self, embedding, hidden_dim, num_layers, num_directions=2, dropout=0.5, fix_embedding=True):\n",
        "    super(GRU_Net, self).__init__()\n",
        "    self.embedding_dim = embedding.size(1)\n",
        "    self.embedding = nn.Embedding(embedding.size(0),embedding.size(1))\n",
        "    self.embedding.weight = torch.nn.Parameter(embedding)\n",
        "    self.embedding.weight.requires_grad = False if fix_embedding else True\n",
        "    self.gru = nn.GRU(embedding_dim, \n",
        "                      hidden_dim, \n",
        "                      num_layers=num_layers, \n",
        "                      batch_first=True, #input and output (batch, seq, feature)\n",
        "                      bidirectional = num_directions == 2\n",
        "                      ) \n",
        "    self.classifier = nn.Sequential( nn.Dropout(dropout),\n",
        "                                         nn.Linear(hidden_dim, 1),\n",
        "                                         nn.Sigmoid() ) #softmax\n",
        "    \n",
        "  def forward(self, input):\n",
        "    input = self.embedding(input)\n",
        "    output, _ = self.gru(input) #input (seq_len, batch, input_size), h0 Defaults to zero\n",
        "    output = self.classifier(output)\n",
        "    return output"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNc7NUpcBFZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        self.label = y\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is None: return self.data[idx]\n",
        "        return self.data[idx], self.label[idx]\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Sgt3hTAmUZ",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzowuqXqCuZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(batch_size, n_epoch, lr, model_dir, train_loader, valid_loader, model, device):\n",
        "    criterion = nn.BCELoss() #binary cross entropy loss function \n",
        "    t_batch = len(train) \n",
        "    v_batch = len(valid) \n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr) # \n",
        "    for epoch in range(n_epoch):\n",
        "        # training module\n",
        "        model.train() # training mode, weights are updated\n",
        "        total_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(train):\n",
        "            inputs = inputs.to(device, dtype=torch.long) \n",
        "            labels = labels.to(device, dtype=torch.float) \n",
        "            optimizer.zero_grad() \n",
        "            outputs = model(inputs) \n",
        "            outputs = outputs.squeeze() \n",
        "            loss = criterion(outputs, labels) # compute training loss\n",
        "            loss.backward() # 算 loss 的 gradient\n",
        "            optimizer.step() \n",
        "            total_loss += loss.item()\n",
        "            print('[ Epoch{}: {}/{} ] loss:{:.3f}'.format(\n",
        "            \tepoch+1, i+1, t_batch, loss.item(), end='\\r'))\n",
        "        print('\\nTrain | Loss:{:.5f}'.format(total_loss/t_batch))\n",
        "\n",
        "        # validation module\n",
        "        model.eval() # fixed weights\n",
        "        with torch.no_grad(): #disables tracking of gradients in autograd.\n",
        "            total_loss, best_loss = 0, 0\n",
        "            for i, (inputs, labels) in enumerate(valid):\n",
        "                inputs = inputs.to(device, dtype=torch.long) \n",
        "                labels = labels.to(device, dtype=torch.float) \n",
        "                outputs = model(inputs) \n",
        "                outputs = outputs.squeeze() \n",
        "                loss = criterion(outputs, labels) \n",
        "                total_loss += loss.item()\n",
        "\n",
        "            print(\"Valid | Loss:{:.5f}\".format(total_loss/v_batch))\n",
        "            curr_loss = total_loss/v_batch\n",
        "            if curr_loss < best_loss:\n",
        "                best_loss = curr_loss\n",
        "                torch.save(model, \"{}/qiqc.model\".format(model_dir))\n",
        "                print('saving model with Loss:{:.5f}'.format(total_loss/v_batch))\n",
        "        print('-----------------------------------------------')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopkeMg2FxX9",
        "colab_type": "text"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc7xSIZxFtZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(batch_size, test_loader, model, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in enumerate(tqdm(test_loader)):\n",
        "            inputs = inputs.to(device, dtype=torch.long)\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze(0) #squeeze removes all demensions with input size of 1, squeeze(0) only \n",
        "    return outputs"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_9uBmzrA1Mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_best_threshold(y_true,output):\n",
        "    best_score = 0 # threshold, score, best_score\n",
        "    threshold = 0\n",
        "    for t in tqdm(np.arange(0.1, 0.501, 0.01)):\n",
        "        score = f1_score(y_true, np.array(output)>t)\n",
        "        if score > best_score:\n",
        "            threshold = t\n",
        "            best_score = score\n",
        "    print('best threshold is {:.4f} with F1 score: {:.4f}'.format(threshold, best_score))\n",
        "    return threshold, best_score"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG4f-5fKGaps",
        "colab_type": "text"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDFKwHwLidbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.gui import tqdm as tqdm_gui\n",
        "tqdm_gui.pandas()"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6wlhrAfP_Wz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "9bc86099-bbfd-42a6-dff1-cec8cb0573b8"
      },
      "source": [
        "%%time\n",
        "# hyperparameters\n",
        "seed = 888\n",
        "kfold = 10\n",
        "batch_size = 128\n",
        "n_workers = 0\n",
        "n_epoch = 5\n",
        "hidden_dim = 150\n",
        "n_layers = 1\n",
        "max_words = 120000\n",
        "\n",
        "seed_everything(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Loading training data\")\n",
        "train_df = pd.read_csv(\"train.csv.zip\")\n",
        "\n",
        "train_x = train_df[\"question_text\"].progress_apply(text_cleaning).values"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tqdm/std.py:726: TqdmExperimentalWarning: GUI is experimental/alpha\n",
            "  t = tclass(*targs, total=total, **tkwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x158.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-f1abf0b44e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_cleaning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tokenize_sentence() missing 1 required positional argument: 'maxlen'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8aZbbB6kA-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "965c6e80-b710-4d19-8497-049a0fe13838"
      },
      "source": [
        "train_x, word_index = tokenize_sentence(train_x, max_words, maxlen=70)\n",
        "y = train_df['target'].values\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-91abf8a1ebf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mglove_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"glove\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-2cf4cf269025>\u001b[0m in \u001b[0;36mload_embedding\u001b[0;34m(typeToLoad, word_index, max_words)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'embeddings/paragram_300_sl999/paragram_300_sl999.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddingg_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mall_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddingg_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgYgmu3ldWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_embedding = load_embedding(\"glove\", word_index, max_words)\n",
        "#embedding_matrix = np.mean([glove_embeddings, paragram_embeddings], axis=0)\n",
        "embedding_matrix = glove_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3QyKmz3ZEPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_df\n",
        "del glove_embedding\n",
        "del word_index\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxMrJizaAiJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "skf = StratifiedKFold(n_split=kfold, shuffle=True, random_state=seed)\n",
        "for i, (train_index, test_index) in enumerate(skf.split(train_x, y)):\n",
        "    if i >= 5: break\n",
        "    print(\"---- cv\", i)\n",
        "    X_train, y_train = train_x[train_index], y[train_index]\n",
        "    X_test, y_test = train_X[test_index], y[test_index]\n",
        "    \n",
        "    train_dataset = MyDataset(X_train, y_train)\n",
        "    val_len = len(y_test) * 0.01\n",
        "    val_index = np.random.choice(test_index, val_len, replace=False) \n",
        "    val_dataset = MyDataset(X_test[val_index], y_test[val_index])\n",
        "    print(\"train size {}, validation size {}\".format(len(train_dataset), len(val_dataset)))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = True,\n",
        "                                                num_workers = n_workers)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = False,\n",
        "                                                num_workers = n_workers)\n",
        "    \n",
        "    model = GRU_Net(embedding_matrix, \\\n",
        "                     hidden_dim=hidden_dim, num_layers=n_layers, num_directions=2, dropout=0.5, fix_embedding=True)\n",
        "    model = model.to(device) \n",
        "    \n",
        "    print(\"Training\")\n",
        "    model_dir = f\"model_cv{i}/\"\n",
        "    training(batch_size, n_epoch, lr, model_dir, train_loader, val_loader, model, device)\n",
        "    \n",
        "    del train_dataset\n",
        "    del train_loader\n",
        "    del val_loader \n",
        "    del val_dataset\n",
        "    gc.collect()\n",
        "\n",
        "    print('\\nload model ...')\n",
        "    model = torch.load(os.path.join(model_dir, \"qiqc.model\")\n",
        "    print(\"Testing\")\n",
        "    test_dataset = MyDataset(X_test)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                                batch_size = batch_size,\n",
        "                                                shuffle = False,\n",
        "                                                num_workers = n_workers)\n",
        "    outputs = testing(batch_size, test_loader, model, device)\n",
        "    result.append(find_best_threshold(y_test,outputs))\n",
        "\n",
        "    del test_dataset\n",
        "    del test_loader\n",
        "    gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}